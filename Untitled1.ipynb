{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65a7580-a3a5-4e0a-b86f-99a26137b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 1392 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://d499e2e2b74edb2869.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d499e2e2b74edb2869.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 605 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 38 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 668 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 676 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 15 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 586 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 19 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 587 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 20 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 586 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 19 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 605 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 38 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 845 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 25 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 668 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 817 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 18 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 605 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 38 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 607 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 37 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 760 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 13 tokens\n",
      "INFO:root:> [query] Total LLM token usage: 1101 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 369 tokens\n"
     ]
    }
   ],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTListIndex, \\\n",
    "    GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import gradio as gr\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEYy\"] = ''\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 512\n",
    "    max_chunk_overlap = 20\n",
    "    chunk_size_limit = 600\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
    "\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "\n",
    "    index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "def chatbot(input_text):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(input_text, response_mode=\"compact\")\n",
    "    return response.response\n",
    "\n",
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.components.Textbox(lines=7, label=\"Enter your text\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"Custom-trained AI Chatbot\")\n",
    "\n",
    "index = construct_index(\"docs\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b2db00-ae65-44fd-9b5c-7175d74e9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: tqdm in c:\\python38\\lib\\site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\python38\\lib\\site-packages (from openai==0.28) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\python38\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\python38\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (3.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python38\\lib\\site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests>=2.20->openai==0.28) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.6.1\n",
      "    Uninstalling openai-1.6.1:\n",
      "      Successfully uninstalled openai-1.6.1\n",
      "Successfully installed openai-0.28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365f054-8ce9-41a3-aa2c-37fe188566e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
