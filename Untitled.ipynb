{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00e9a9a-0674-406c-b954-39468b32c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: openai in c:\\python38\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: anyio<5,>=3.5.0 in c:\\python38\\lib\\site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied, skipping upgrade: httpx<1,>=0.23.0 in c:\\python38\\lib\\site-packages (from openai) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: distro<2,>=1.7.0 in c:\\python38\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>4 in c:\\python38\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<5,>=4.7 in c:\\python38\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied, skipping upgrade: sniffio in c:\\python38\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pydantic<3,>=1.9.0 in c:\\python38\\lib\\site-packages (from openai) (1.10.7)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.8 in c:\\python38\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: httpcore<0.18.0,>=0.15.0 in c:\\python38\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\python38\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\python38\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied, skipping upgrade: h11<0.15,>=0.13 in c:\\python38\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0cb184-a4e7-41b9-bbc9-9a9e13abf8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bcbea8-0520-4887-aaa3-8f8a608b6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_text(text):\n",
    "    # max_tokens = 50\n",
    "    try:\n",
    "      prompt = f\"Paraphrase the following text with less number of words: {text}\"\n",
    "      response = openai_chat_completion(prompt,)\n",
    "      paraphrased_text = response\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      paraphrased_text = ''\n",
    "    print(\"text = \",paraphrased_text)\n",
    "    return paraphrased_text\n",
    "\n",
    "\n",
    "def read_excel(file_path):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    return xls\n",
    "\n",
    "\n",
    "def read_sheet(excel, sheet):\n",
    "    df = pd.read_excel(excel, sheet)\n",
    "    return df\n",
    "\n",
    "\n",
    "def paraphrase_and_store(sentenceDF):\n",
    "    sentenceDF[\"Script\"] = sentenceDF[\"Original Sentence\"].apply(\n",
    "        lambda x: paraphrase_text(x.split('.')[0]) if isinstance(x, str) else \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54015a5f-c73d-4bed-922e-aef5e6e358a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = \"Mixtape _ New Narrative Spreadsheet Template 2.xlsx\"\n",
    "xls = read_excel(excel_file_path)\n",
    "df = read_sheet(xls, 'Sentence Analysis')\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "\n",
    "sentences = df['Original Sentence']\n",
    "hook = df['Hook']\n",
    "superlatives = df['Superlatives']\n",
    "cta = df['CTA']\n",
    "before = df['Before']\n",
    "after = df['After']\n",
    "\n",
    "data = []\n",
    "\n",
    "for count, i in enumerate(sentences):\n",
    "  sent_type = ''\n",
    "  if hook.iloc[count] == 'x':\n",
    "    sent_type += 'Hook'\n",
    "  if superlatives.iloc[count] == 'x':\n",
    "    sent_type += ' Superlatives'\n",
    "    sent_type = sent_type.strip()\n",
    "  if cta.iloc[count] == 'x':\n",
    "    sent_type += ' CTA'\n",
    "    sent_type = sent_type.strip()\n",
    "  if before.iloc[count] == 'x':\n",
    "    sent_type += ' Before'\n",
    "    sent_type = sent_type.strip()\n",
    "  if after.iloc[count] == 'x':\n",
    "    sent_type = ' After'\n",
    "    sent_type = sent_type.strip()\n",
    "  \n",
    "  if sent_type != '':\n",
    "    sent_type = sent_type.replace(' ',',')\n",
    "    d = {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": i}, {\"role\": \"assistant\", \"content\": sent_type}]}\n",
    "    data.append(d)\n",
    "    # data.append({'prompt': i, 'completion': sent_type})\n",
    "    # print(f'{i}: {sent_type}')\n",
    "\n",
    "with jsonlines.open('output2.jsonl', 'w') as writer:\n",
    "    writer.write_all(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b64c6-38ad-428c-9fef-56d3d91029bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c874e7-08fc-4a65-ad7a-5286c86f93bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!export OPENAI_API_KEYy='' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de244f34-6c50-46d1-adc5-8af959157baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='' )\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"output2.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "model = client.fine_tuning.jobs.create(\n",
    "  training_file=file.id,\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437b0771-c3d9-43c8-8566-08f0839dff9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-duWEhPfZVw2Z83jOsfi2WjI1', bytes=17690, created_at=1704102502, filename='output2.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1a8710-0451-4aca-9be4-7e55831b5ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-kytZOQOYvwPBBjcporxeJsbE', created_at=1704102503, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-P7gz0zBNRxbe2aHfYNocYNKv', result_files=[], status='validating_files', trained_tokens=None, training_file='file-duWEhPfZVw2Z83jOsfi2WjI1', validation_file=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa2935d-4bd0-48d1-b57e-348c4805f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c06539d1-fa16-4e47-89ef-7060f371eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-kytZOQOYvwPBBjcporxeJsbE', created_at=1704102503, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:social-generation::8c9LIsuM', finished_at=1704103067, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-P7gz0zBNRxbe2aHfYNocYNKv', result_files=['file-yBMQjPt7T3hTlgTBRUvKFRiC'], status='succeeded', trained_tokens=9282, training_file='file-duWEhPfZVw2Z83jOsfi2WjI1', validation_file=None), FineTuningJob(id='ftjob-f8qekfL0zlO9NA2SMcdGJ3Ab', created_at=1704054063, error=None, fine_tuned_model='ft:babbage-002:social-generation::8bwdL8I6', finished_at=1704054214, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='babbage-002', object='fine_tuning.job', organization_id='org-P7gz0zBNRxbe2aHfYNocYNKv', result_files=['file-ZTZI2uMG1tC10aYH11ilZ7zH'], status='succeeded', trained_tokens=3432, training_file='file-OMIrIKix70YlHTfaf6qt7RL2', validation_file=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cea0a4-9817-4ae6-8f57-6b6f462e82b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-kytZOQOYvwPBBjcporxeJsbE', created_at=1704102503, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-P7gz0zBNRxbe2aHfYNocYNKv', result_files=[], status='running', trained_tokens=None, training_file='file-duWEhPfZVw2Z83jOsfi2WjI1', validation_file=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-kytZOQOYvwPBBjcporxeJsbE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c444cd8-a1b9-4dce-aa94-824c3d39659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-nZ4eiIRFtyV2nQyFcNfLEvpe', created_at=1704102536, level='info', message='Fine-tuning job started', object='fine_tuning.job.event', data=None, type='message'), FineTuningJobEvent(id='ftevent-Q4G2WIiKM5Up2Ct4k4YgyBt9', created_at=1704102536, level='info', message='Files validated, moving job to queued state', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-24I4KY0MHQO8mCjMpB8Tuv1u', created_at=1704102503, level='info', message='Validating training file: file-duWEhPfZVw2Z83jOsfi2WjI1', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-W0NDKZL8dVkM2gZNB78N9HPN', created_at=1704102503, level='info', message='Created fine-tuning job: ftjob-kytZOQOYvwPBBjcporxeJsbE', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-kytZOQOYvwPBBjcporxeJsbE\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59581716-4807-4c50-8f73-37ba169759c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:social-generation::8c9LIsuM\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Can you find all sentences which are hooks?\"},\n",
    "  ]\n",
    ")\n",
    "# print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d3b204d-ae97-4566-a762-5cd2f6f75766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='O+HOOK', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790558f-bd80-4581-bd7b-4b04e81bd5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
